# mariah_carey_christmas

'Mariah Carey' - 'All I want for Christmas is you' 음원 순위 예측 프로젝트

제작기간 : 2021.01.03 ~ 2021.01.07

# 프로젝트 키워드

- 시계열 데이터

- 개인프로젝트

- LSTM

# 프로젝트 시작 동기

한국에 벚꽃연금이 있다면, 미국은 이 사람이다.

'Mariah Carey'의 'All I want for Christmas is you'는 10년이 넘는 기간동안 매년 크리스마스가 다가오면 서서히 모습을 드러내고, 1위를 탈환한 뒤 급격하게 다시 순위표에서 사라지는 대표적인 음원이다. 이 음원의 이러한 패턴은 기온과 연관관계가 있을까? 하는 생각이 시작의 발단이었다.

# 원하는 결과물

2011년 2월부터 2021년 1월까지의 itunes 음원순위와, 동일 기간 기온 데이터를 토대로 기온에 따른 음원 순위 변화를 예측해본다.

# 사용 기술

- Python3 : 데이터 스크래핑을 비롯하여, 모델 생성과 학습 등 전반에 걸쳐 다용도로 사용되었다.

- BeautifulSoup : 정적인 페이지를 스크래핑하는 데 사용되었다(음원순위 페이지).

- Selenium : 동적인 페이지를 스크래핑하는 데 사용되었다(기온 페이지).

- TensorFlow2 : 수집한 데이터들을 일정한 기준에 따라 학습하고 모델을 생성하였다.

- Keras : TensorFlow2를 활용하는 데 효과적인 언어이다.

- Google Colab : 노트북의 하드웨어적 한계를 극복하고자, 가상 환경에서 빠른 진행을 위해 사용되었다.

# 프로젝트 과정

## 1. 데이터 수집 (총 기간 : 2021.01.03 ~ 2021.01.06)

### 1) 일간 음원 순위 스크래핑(2011.02 ~ 2021.01)

- itunes 음원 순위 : Billboard는 순위표 진입에 각종 제한(일정 기준을 충족하지 못하면 오래된 곡은 차트아웃)이 있고, 'All I want for Christmas is you'의 음원 순위를 스크래핑 할 수 있는 기준의 데이터는 유료로 판매하고 있어, itunes 음원 순위를 선정.

- 세계, 미국, 영국 음원 순위 : 세계 음원 순위는 프로젝트 목적의 핵심적인 대상이고, 미국과 영국은 각각 세계 1위, 2위의 음악 시장을 보유하고 있어 세계 음원 순위 예측에 필요한 데이터이다. 정적 페이지로 BeautifulSoup을 통해 스크래핑.

### 2) 일간 기온 데이터 스크래핑(2011.02 ~ 2021.01)

- 미국, 영국 기온 데이터 : 최대 음악 시장 보유국들의 기온을 스크래핑하였다. 겨울에 크리스마스를 맞는 국가이기도 하다. 화씨 데이터를 섭씨 데이터로 변환.

---

## 2. 데이터 병합 및 CSV 파일로의 저장

- 수집한 음원 순위 데이터와 기온 데이터를 병합하고, 데이터 활용을 위해 CSV 파일로 저장했다.

---

## 3. 데이터 가공 (총 기간 : 2020.01.06 ~ 2020.01.07)

### 1) 데이터 정제

- 데이터의 형태를 파악하고 결측값을 대체하였다. 음원 데이터는 400(350위까지 기록됨) 또는 앞 순위, 기온 데이터는 전 날의 기온으로 대체.

### 2) 데이터 스케일링

- 데이터를 0부터 1사이의 척도로 변환하여 명확한 관계가 드러나도록 함.

### 3) 훈련 데이터, 테스트 데이터 분리

- 날짜(2018-12-31)를 기준으로 전자는 훈련, 후자는 테스트 데이터로 정함.

### 4) 윈도우 생성

- 학습을 위한 윈도우(90일치씩)를 생성하여 데이터셋을 생성하였다.

---

## 4. 데이터 학습 (총 기간 : 2020.01.06 ~ 2020.01.07)

### 1) 데이터 훈련 지표 설정

- LSTM : 여러 데이터들 사이에서 과거의 순위를 축적하여 학습하는 데 적합.

- return_sequences = True : LSTM 레이어를 여러 개로 쌓기 위함.

- input_shape=(90, 5) : 데이터 입력 형태. 윈도우 90개, 데이터 5종

- activation = 'relu' : 스케일링한 데이터의 정확도를 올리기 위함

### 2) 데이터 훈련

- EarlyStopping : 조기에 학습이 완료될 시 종료될 수 있도록 함.

- TensorFlow2를 이용하여 훈련함.

---

## 5. 데이터 결과 도출 및 시각화 (총 기간 : 2020.01.06 ~ 2020.01.07)

### 1) 데이터 결과 도출

- 학습된 모델을 토대로 테스트 값과 예측값을 비교함

- 학습된 모델과 실제 값 사이의 오차를 측정

### 2) 결과 시각화

- pandas의 기본 기능을 사용한 그래프를 통해 테스트 값, 예측값을 비교함.

- pandas의 기본 기능을 사용한 그래프를 통해 오차 양상을 표현함.

---

# 데이터의 형태

- 초기

   3608 행, 6열

   0   date    3608 non-null   int64  
   
   1   WDRank  3607 non-null   float64
   
   2   USRank  3562 non-null   float64
   
   3   USTemp  3608 non-null   float64
   
   4   UKRank  3553 non-null   float64
   
   5   UKTemp  3608 non-null   float64

   dtypes: float64(5), int64(1)
   
- 정제 후

  3608 행, 6열

   0   date    3608 non-null   float64  
   
   1   WDRank  3608 non-null   float64
   
   2   USRank  3608 non-null   float64
   
   3   USTemp  3608 non-null   float64
   
   4   UKRank  3608 non-null   float64
   
   5   UKTemp  3608 non-null   float64

   dtypes: float64(6)
   
   

# 추후 발전 방향

- 단순히 순위변화를 예측하는 것이 아니라, 그 날짜를 예측해보고자 한다.

- 순위 예측 모델을 프로그램화 하여, 기온과 음원 순위 입력 시 세계 음원 순위와 날짜를 예측하고자 한다.

- 클라우드 서버 배포 : 미국에서는 'Mariah Carey'의 'All I want for Christmas is you'를 크리스마스 즈음에 무조건적으로 들어야하는 음악으로 이미 하나의 '밈'으로 자리잡았다고 한다. 배포가 된다면 모두에게 즐거움을 주는 프로그램이 될 수 있을 것이라고 생각한다.

- 벚꽃 엔딩의 음원 데이터를 수집하여, 국내 순위 변동을 예측해도 흥미로울 것이라고 생각한다.

- 시각화가 부족한 듯 하여 seaborn이나 tableau, excel의 사용을 고려하고 있다.

# 프로젝트를 통한 결론

- 개인적으로 Google Colab(이하 코랩)을 처음 써본 프로젝트였는데 그 성능에 정말 많이 놀랐다. 일례로 음원순위 스크래핑에 노트북은 약 5시간 정도 소요되었는데, 코랩은 1시간여만에 스크래핑을 완료하였다. TensorFlow와의 궁합도 무척 좋아 설치없이 사용하고 빠른 속도로 실행되는 것에 감탄이 나올 정도였다.

- 리스트를 만들 때 공백 리스트를 항상 위에 몰아놓는 습관이 있었는데, 이번 스크래핑 과정에서 실수로 수집한 데이터를 여러 번 날려먹었다. 덕분에 각 함수나 과정을 나누어 공백 리스트를 설정하게 되었다.

- 스크래핑한 데이터를 리스트로 만들고, 병합하는 과정에서 병합 실수로 또 수집한 데이터를 여러 번 날려먹었다. 때문에 복제 리스트를 만들어 데이터를 보호하는 것의 중요성을 깨달았다.
